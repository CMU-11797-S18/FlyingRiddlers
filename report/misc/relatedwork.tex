
\section{Relevant Literature}
\label{lit}

The Question Answering problem is immensely popular among NLP researchers and large industrial research labs all over the world. The release of the SquAD data set \cite{squad} boosted this interest as many researchers began to use this data set to evaluate their approaches. However, the SquAD data set is only used to evaluate extractive question-answering systems and hence doesn't allow for free-form answers. The state of the art model for this problem presently is the Dynamic Co-Attention Network (DCN) from Xiong et al.  \cite{DCN}, the ensemble model of which presently holds the top spot on the SquAD leader board. The DCN first fuses co-dependent representations of the question and the document in order to focus on relevant parts of both. Then a dynamic pointing decoder iterates over potential answer spans. This iterative procedure enables the model to recover from initial local maxima corresponding to incorrect answers. \\

Other prominent works include the R-Net networks from Microsoft Research Asia \cite{Rnet} who introduce self matching networks to tackle this problem. They first match the question and passage with gated attention-based recurrent networks to obtain the question-aware passage representation. Then they propose a self-matching attention mechanism to refine the representation by matching the passage against itself, which effectively encodes information from the whole passage. Finally they employ the pointer networks to locate the positions of answers from the passages.\\

The Bidaf network from Seo et al \cite{bidaf} was one of the first landmark papers to demonstrate the effectiveness of attention based bidirectional recurrent networks on the task of Machine Comprehension.  They introduced a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Many subsequent works on the problem now build on top of the Bidaf network.\cite{Sedt} from CMU and \cite{Reasonet} for Microsoft Research Redmond are some of the other prominent works on this problem. In \cite{Sedt} the authors encode the information from syntactic trees into the vector embeddings and use this added structured syntactic knowledge to improve their results on this task. In \cite{Reasonet}, the authors propose a reinforcement learning based approach to determine how many passes should the network make over the knowledge base during answer generation thereby doing away with restriction of fixed number of passes over the knowledge base.\\

Biomedical Question answering has always been a hot topic of research among the QA community at large due to the relative significance of the problem and the challenge of dealing with a non standard vocabulary and vast knowledge sources. The BioASQ challenge has seen large scale participation from research groups across the world. One of the most prominent among such works is from Chandu et al. \shortcite{khyati-paper} who experiment with different biomedical ontologies, agglomerative clustering, Maximum Marginal Relevance (MMR) and sentence compression. However, they only address the ideal answer generation with their model. Peng et al. \shortcite{fudan} in their BioASQ submission use a 3 step pipeline for generating the exact answers for the various question types. The first step is question analysis where they subdivide each question type into finer categories and classify each question into these subcategories using a rule based system. They then perform candidate answer generation using POS taggers and use a word frequency-based approach to rank the candidate entities. Wiese et al. \shortcite{fastqa} propose a neural QA based approach to answer the factoid and list type questions where they use FastQA: a machine comprehension based model \cite{fastqa-squad} and pre-train it on the SquaD dataset \cite{squad} and then finetune it on the BioASQ dataset. They report state of the art results on the Factoid and List type questions on the BioASQ dataset. Another prominent work is from Sarrouti and Alaoui \shortcite{usmba} who handle the generation of the exact answer type questions. They use a sentiment analysis based approach to answer the yes/no type questions making use of SentiWordNet for the same. For the factoid and list type questions they use UMLS metathesaurus and term frequency metric for extracting the exact answers. \\ %They also use the BM25 model and UMLS concepts for retrieving the ideal answers. \\

Despite the popularity of Machine Comprehension problems, very little work has been done on free-form answer generation for questions. The biggest reasons likely include the lack of large standard data sets, difficulty in evaluation and the inherent difficulty of `human-like' natural language generation. One of the only existing data sets for this problem is the MS Marco dataset released by Microsoft \cite{msmarco}. The top positions on this leader board are held by modifications of the RNet \cite{Rnet} and Reasonet \cite{Reasonet} algorithms. Most of these approaches generate the answer by using an attention based bidirectional LSTM network to generate the answer word-by-word conditioned on the knowledge base, question and the best answer span. However, most of these answers lack syntactic coherence, retention of long term dependencies and human-like answer quality, which have been the primary problems with free-form natural language generation. Here we explore approaches to try and solve these problems and try to improve the performance on Machine Comprehension and free-form response generation.\\
